# -*- coding: utf-8 -*-
"""cocodataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1X5oKkjf32rRfu_5PMay4L6N4jsnfi42g
"""

!pip install CocoDataset==0.1.2

!wget http://images.cocodataset.org/annotations/annotations_trainval2014.zip
!unzip /content/annotations_trainval2014.zip

from google.colab import drive
drive.mount('/content/drive')

from coco_dataset import coco_dataset_download as cocod
class_name='person'  #class name example
images_count=1500       #count of images
annotations_path='/content/annotations/instances_train2014.json' #path of coco dataset annotations
#call download function
cocod.coco_dataset_download(class_name,images_count,annotations_path)

import shutil

shutil.move('/content/person3', '/content/drive/MyDrive/Datasets')

from coco_dataset import coco_dataset_download as cocod
class_name='car'  #class name example
images_count=1000       #count of images
annotations_path='/content/annotations/instances_train2014.json' #path of coco dataset annotations
#call download function
cocod.coco_dataset_download(class_name,images_count,annotations_path)

import shutil

shutil.move('/content/car1', '/content/drive/MyDrive/Datasets')

from coco_dataset import coco_dataset_download as cocod
class_name='person'  #class name example
images_count=1500       #count of images
annotations_path='/content/annotations/instances_train2014.json' #path of coco dataset annotations
#call download function
cocod.coco_dataset_download(class_name,images_count,annotations_path)

import shutil

shutil.move('/content/bench', '/content/drive/MyDrive/Datasets')

from coco_dataset import coco_dataset_download as cocod
class_name='dog'  #class name example
images_count=3500       #count of images
annotations_path='/content/annotations/instances_train2014.json' #path of coco dataset annotations
#call download function
cocod.coco_dataset_download(class_name,images_count,annotations_path)

import shutil

shutil.move('/content/cat1', '/content/drive/MyDrive/Datasets')

from coco_dataset import coco_dataset_download as cocod
class_name='cat'  #class name example
images_count=3500       #count of images
annotations_path='/content/annotations/instances_train2014.json' #path of coco dataset annotations
#call download function
cocod.coco_dataset_download(class_name,images_count,annotations_path)











import shutil

shutil.move('/content/bicycle', '/content/drive/MyDrive/Datasets')

from coco_dataset import coco_dataset_download as cocod
class_name='chair'  #class name example
images_count=3500       #count of images
annotations_path='/content/annotations/instances_train2014.json' #path of coco dataset annotations
#call download function
cocod.coco_dataset_download(class_name,images_count,annotations_path)

import shutil

shutil.move('/content/chair', '/content/drive/MyDrive/Datasets')

from coco_dataset import coco_dataset_download as cocod
class_name='chair'  #class name example
images_count=1000       #count of images
annotations_path='/content/annotations/instances_train2014.json' #path of coco dataset annotations
#call download function
cocod.coco_dataset_download(class_name,images_count,annotations_path)

from coco_dataset import coco_dataset_download as cocod
class_name='motorcycle'  #class name example
images_count=3500       #count of images
annotations_path='/content/annotations/instances_train2014.json' #path of coco dataset annotations
#call download function
cocod.coco_dataset_download(class_name,images_count,annotations_path)

import shutil

shutil.move('/content/motorcycle', '/content/drive/MyDrive/Datasets')

from coco_dataset import coco_dataset_download as cocod
class_name='cat'  #class name example
images_count=2000       #count of images
annotations_path='/content/annotations/instances_train2014.json' #path of coco dataset annotations
#call download function
cocod.coco_dataset_download(class_name,images_count,annotations_path)

import shutil

shutil.move('/content/cat2', '/content/drive/MyDrive/Datasets')

from coco_dataset import coco_dataset_download as cocod
class_name='dog'  #class name example
images_count=00       #count of images
annotations_path='/content/annotations/instances_train2014.json' #path of coco dataset annotations
#call download function
cocod.coco_dataset_download(class_name,images_count,annotations_path)

import shutil

shutil.move('/content/dog', '/content/drive/MyDrive/Datasets')

import os

def count_files(folder_path):
  """Counts the number of files in a given folder.

  Args:
    folder_path: The path to the folder.

  Returns:
    The number of files in the folder.
  """
  file_count = 0
  for filename in os.listdir(folder_path):
    # Skip hidden files and folders like .ipynb_checkpoints
    if filename.startswith('.'):
      continue
    file_path = os.path.join(folder_path, filename)
    if os.path.isfile(file_path):  # Check if it's a file
      file_count += 1
  return file_count

# Example usage:
folder_to_count = '/content/drive/MyDrive/Datasets'  # Replace with your folder path
file_count = count_files(folder_to_count)
print(f"Number of files in '{folder_to_count}': {file_count}")



import os
import shutil

# Define source folder (where 10 subfolders are)
source_folder = "/content/drive/MyDrive/Datasets"  # Change this to your actual path

# Define destination folder (where all images will be merged)
destination_folder = "/content/drive/MyDrive/merged_dataset"

# Create destination folder if it doesn't exist
os.makedirs(destination_folder, exist_ok=True)

# Iterate through each subfolder and move images
for subdir in os.listdir(source_folder):
    subdir_path = os.path.join(source_folder, subdir)

    if os.path.isdir(subdir_path):  # Ensure it's a directory
        for file in os.listdir(subdir_path):
            file_path = os.path.join(subdir_path, file)

            # Ensure it's an image file
            if file.lower().endswith((".jpg", ".jpeg", ".png")):
                shutil.copy(file_path, os.path.join(destination_folder, file))

print("Merging completed successfully!")

pip install ultralytics

import os
from ultralytics import YOLO
from collections import defaultdict
from PIL import Image

# Path to your datasets folder
dataset_path = "/content/drive/MyDrive/Datasets"

# 9 specified classes
target_classes = ['bench', 'bicycle', 'bus', 'car', 'cat', 'chair', 'dog', 'motorcycle', 'person']
class_name_to_id = {name: i for i, name in enumerate(target_classes)}

# Load your YOLO model (YOLOv8 assumed here)
model = YOLO('yolo11m.pt')  # or use 'yolov5l.pt' if you're using YOLOv5

# Filter model to detect only our 9 classes
model.classes = list(class_name_to_id.values())

# Counter
total_counts = defaultdict(int)

# Supported extensions
image_exts = ['.jpg', '.jpeg', '.png']

# Loop through all subfolders
for root, _, files in os.walk(dataset_path):
    for file in files:
        if os.path.splitext(file)[1].lower() in image_exts:
            image_path = os.path.join(root, file)

            # Run prediction
            results = model(image_path, verbose=False)[0]

            for box in results.boxes:
                class_id = int(box.cls)
                if class_id in class_name_to_id.values():
                    total_counts[class_id] += 1

# Final result
print("\n✅ Object Detection Count Across Dataset:\n")
for name, idx in class_name_to_id.items():
    print(f"{name.capitalize()} ({idx}): {total_counts[idx]}")

import os
import hashlib
from collections import defaultdict

# Define the root datasets directory
DATASETS_DIR = "/content/drive/MyDrive/Datasets"

# Supported image file extensions
IMAGE_EXTENSIONS = {'.jpg', '.jpeg', '.png', '.bmp', '.webp'}

# Storage
file_hashes = defaultdict(list)
total_files = 0

# Function to compute hash of a file
def compute_hash(filepath):
    hash_func = hashlib.md5()
    with open(filepath, 'rb') as f:
        for chunk in iter(lambda: f.read(4096), b""):
            hash_func.update(chunk)
    return hash_func.hexdigest()

# Walk through all files
for root, _, files in os.walk(DATASETS_DIR):
    for file in files:
        ext = os.path.splitext(file)[-1].lower()
        if ext in IMAGE_EXTENSIONS:
            total_files += 1
            full_path = os.path.join(root, file)
            file_hash = compute_hash(full_path)
            file_hashes[file_hash].append(full_path)

# Detect duplicates
duplicates = {h: paths for h, paths in file_hashes.items() if len(paths) > 1}

# Summary
print(f"\n📦 Total image files: {total_files}")
print(f"🔁 Total duplicate groups: {len(duplicates)}")

# Show some duplicates
if duplicates:
    print("\n⚠️ Example duplicate groups:")
    for i, (h, paths) in enumerate(duplicates.items()):
        print(f"\n🧾 Duplicate Group {i+1}:")
        for path in paths:
            print(f"   - {path}")
        if i == 4:  # Limit output
            break
else:
    print("✅ No duplicate files found.")

























